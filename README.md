# Trustworthy AI: algorithm assessment BB

This part must be rewritten.

Here are followig the links to design documents :

- [LORIA's LOLA platform] (docs/loria/design-document-LORIA.md)
- [AffectLog AffectLog360 platform](docs/affectlog/design-document-AffectLog.markdown)
- [UoK Carisma platform](docs/affectlog/ddesign-document-carisma.markdown)



<!--In the dynamic world of AI, LORIA and Affectlog's Trustworthy AI Assessment initiative is central to fostering trust and transparency. This program integrates two sophisticated and complementary platforms â€” LORIA's audit platform for data and algorithms and Affectlog's safety assessment platform. 

These platforms improve the transparency and safety of AI technologies, which are critical for stakeholders in the education, healthcare and technology sectors.
By providing detailed insights and safety assessments, they set a new standard for trust and ethical AI use.

These two platforms are described respectively :

- LORIA's LOLA platform : [here](https://github.com/Prometheus-X-association/t-ai/blob/loria/README.md)
- AffectLog AfectLog360 platform: [here](https://github.com/Prometheus-X-association/t-ai/blob/AffectLog360-dd/README.md)

This approach is supplemented by an approach developed by Fraunhofer ISST and University of Koblenz that implements automated analyses of software models and AI trustworthiness indicators with respect to the aspects explainability, data security, privacy, and fairness.
More specifically, it is planned to develop a new approach to create compliance documents that are required by AI providers to fulfill documentation obligations as defined in EU's AI Act. A second contribution is an approach that allows for the assessment of AI enabled systems regarding AI specific security issues as identified by the "Open Worldwide Application Security Project (OWASP)" community by using models of those systems.
-->